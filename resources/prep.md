# 🎯 AI Olympiad Learning Plan

## 📚 Table of Contents
- [Week 1: Core ML & Data Handling](#week-1-core-ml--data-handling)
- [Week 2: Advanced ML & Model Optimization](#week-2-advanced-ml--model-optimization)
- [Week 3: Deep Learning Basics](#week-3-deep-learning-basics-pytorch-focus)
- [Week 4: CNNs & Computer Vision](#week-4-cnns--computer-vision)
- [Week 5: NLP & Transformers](#week-5-nlp--transformers)
- [Week 6: Final Preparation](#week-6-final-preparation--olympiad-practice)

---

### Week 1: Core ML & Data Handling 🐍
#### Resources
- 🎦 [Python Crash Course](https://www.youtube.com/watch?v=rfscVS0vtbw)
- 📊 [NumPy Basics](https://www.datacamp.com/community/tutorials/python-numpy-tutorial)
- 🐼 [Pandas Tutorial](https://www.kaggle.com/learn/pandas)
- 📊 [Matplotlib & Seaborn Guide](https://www.youtube.com/watch?v=HVgLOWx79bI)
- 🤖 [Scikit-learn Intro](https://www.kaggle.com/learn/intro-to-machine-learning)

#### Learning Objectives
- Python Basics (loops, functions, OOP)
- NumPy & Pandas for Data Handling
- Matplotlib & Seaborn for Data Visualization
- Scikit-learn Basics (Train/Test Split, Pipelines)
- Implement Linear Regression, Logistic Regression

---

### Week 2: Advanced ML & Model Optimization 📈
#### Resources
- 🌳 [SVM, Decision Trees](https://www.kaggle.com/learn/intermediate-machine-learning)
- ⚙️ [Hyperparameter Tuning Guide](https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/)
- 🚀 [XGBoost Guide](https://xgboost.readthedocs.io/en/stable/)
- 📊 [Model Evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html)

#### Learning Objectives
- SVM, Gradient Boosting (XGBoost, LightGBM)
- Hyperparameter Tuning (GridSearchCV, RandomizedSearchCV)
- Cross-Validation, Regularization (L1, L2, Early Stopping)
- Unsupervised Learning: K-Means, PCA, DBSCAN
- Model Evaluation (Precision, Recall, ROC/AUC)

---

### Week 3: Deep Learning Basics (PyTorch Focus) 🔥
#### Resources
- ⚡ [PyTorch Beginner Guide](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
- 🧠 [Neural Networks from Scratch](https://www.youtube.com/watch?v=aircAruvnKk)
- 📊 [Activation Functions](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html)
- 📉 [Gradient Descent & Backpropagation](https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd)

#### Learning Objectives
- PyTorch Basics: Tensors, Autograd
- Perceptron, Gradient Descent, Backpropagation
- Activation Functions (ReLU, Sigmoid, Tanh)
- Building MLP (Multilayer Perceptron)
- Optimization (SGD, Adam, Learning Rate Scheduling)

---

### Week 4: CNNs & Computer Vision 👁️
#### Resources
- 🔍 [CNN Explained](https://cs231n.github.io/convolutional-networks/)
- 🖼️ [PyTorch CNN Guide](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)
- 🔄 [Data Augmentation Techniques](https://towardsdatascience.com/data-augmentation-techniques-in-python-f82eebb9d3e6)
- 📚 [Transfer Learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)

#### Learning Objectives
- Convolutional Layers, Pooling (Max, Average)
- Building CNN from scratch in PyTorch
- Training CNN on CIFAR-10 / MNIST
- Transfer Learning (ResNet, MobileNet, EfficientNet)
- Data Augmentation Techniques

---

### Week 5: NLP & Transformers 🖍️
#### Resources
- 🌦️ [Word2Vec & GloVe](https://www.kaggle.com/code/jeffd23/visualizing-word-vectors-t-sne)
- 🤖 [Transformers Explained](https://jalammar.github.io/illustrated-transformer/)
- 🔧 [BERT Fine-Tuning](https://huggingface.co/docs/transformers/training)
- 📊 [Text Classification with BERT](https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894)

#### Learning Objectives
- Word Embeddings (Word2Vec, GloVe, FastText)
- Transformer Basics (Self-Attention, Positional Encoding)
- Text Classification using BERT/GPT
- Fine-Tuning Pre-Trained Models
- Question Answering & Chatbots

---

### Week 6: Final Preparation & Olympiad Practice 🏆
#### Resources
- 📊 [Weights & Biases (WandB)](https://wandb.ai/)
- 🚀 [FastAPI for Model Deployment](https://fastapi.tiangolo.com/)
- 🔥 [AI Olympiad Past Problems](https://www.kaggle.com/competitions)

#### Learning Objectives
- End-to-End Model Deployment (FastAPI, Streamlit)
- Weights & Biases (Experiment Tracking)
- Solve AI Olympiad past problems
- Optimize models for efficiency

---

> 💡 **Pro Tips:**
> - Use the table of contents for quick navigation
> - Track your progress with checkboxes ✅
> - Join AI communities for support
> - Practice with real datasets daily
> - Document your learning journey
