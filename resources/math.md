# 🚀 50-Hour Math Sprint for Data Science & ML Olympiad

**Goal:** Build a strong *working understanding* of key math concepts (stats, linear algebra, calculus, geometry) fast and efficiently.

---

## ✅ 1️⃣ Stats & Probability (~15 hours)

**Key Topics:**
- Mean, median, mode
- Variance, standard deviation
- Probability rules (addition, multiplication)
- Conditional probability, Bayes theorem
- Probability distributions: Normal, Binomial
- Correlation vs causation
- Hypothesis testing basics

**Resources:**
- 📺 [Khan Academy - Statistics & Probability](https://www.khanacademy.org/math/statistics-probability)
- 📺 [StatQuest (YouTube) - Bayes, Distributions, Hypothesis Testing](https://www.youtube.com/c/joshstarmer)
- 🌐 [Seeing Theory - Interactive](https://seeing-theory.brown.edu)
- 📝 Hands-on: Use Pandas + Seaborn to explore datasets (`sns.load_dataset('titanic')`)

---

## ✅ 2️⃣ Linear Algebra (~12 hours)

**Key Topics:**
- Vectors & matrices (addition, multiplication)
- Dot product, transpose
- Matrix multiplication (np.dot / @ operator)
- Linear transformations
- PCA intuition (eigenvalues, eigenvectors)

**Resources:**
- 📺 [3Blue1Brown - Essence of Linear Algebra (Ep 1-4, Ep 10)](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)
- 📖 [Numpy Linear Algebra Quickstart](https://numpy.org/doc/stable/user/quickstart.html)
- 📺 [StatQuest - PCA](https://www.youtube.com/watch?v=FgakZw6K1QQ)
- 📝 Code: `np.array`, `np.dot`, `np.linalg.eig`, `sklearn.decomposition.PCA`

---

## ✅ 3️⃣ Calculus (Gradients + Optimization) (~8 hours)

**Key Topics:**
- Derivatives, gradients
- Chain rule
- Gradient descent intuition

**Resources:**
- 📺 [3Blue1Brown - Calculus: The Essence of Change](https://www.youtube.com/watch?v=WUvTyaaNkzM)
- 📺 [StatQuest - Gradient Descent](https://www.youtube.com/watch?v=sDv4f4s2SB8)
- 📖 [Khan Academy - Calculus Basics](https://www.khanacademy.org/math/calculus-1)
- 📝 Code: Write gradient descent for `f(x) = x^2`, use `sklearn.linear_model.SGDRegressor`

---

## ✅ 4️⃣ Geometry (Vectors & Distance) (~7 hours)

**Key Topics:**
- Euclidean distance
- Cosine similarity
- Basic clustering (KMeans intuition)

**Resources:**
- 📺 [StatQuest - KMeans Clustering](https://www.youtube.com/watch?v=4b5d3muPQmA)
- 📖 [sklearn Metrics - pairwise_distances](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html)
- 📖 [Khan Academy - Distance & Vectors](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces)
- 📝 Code: `np.linalg.norm`, `sklearn.metrics.pairwise.cosine_similarity`, `KMeans`

---

## ✅ 5️⃣ Discrete Math (Combinatorics Basics) (~3 hours)

**Key Topics:**
- Factorials
- Permutations & combinations
- Set theory basics

**Resources:**
- 📺 [Khan Academy - Combinatorics](https://www.khanacademy.org/math/statistics-probability/probability-library)
- 📖 [Python `math.factorial` / `scipy.special.comb`](https://docs.python.org/3/library/math.html#math.factorial)
- 📝 Quick practice: Count combinations in simple problems (e.g., lotto numbers)

---

## ✅ 6️⃣ Review & Wrap (~5 hours)

**Do:**
- Sketch a **mindmap** of:
    - Stats pipeline: how mean/std + distribution + Bayes fit
    - Linear algebra: how matrices + PCA fit
    - Gradient descent: how optimization works
- Small recap code project:
    - Load Iris dataset
    - Describe (mean, std)
    - PCA 2D plot
    - KMeans clustering
    - Simple model (LogisticRegression)

**Resource:** Your notes + Kaggle Notebooks for recap inspiration

---

# 🔥 Pro Tip:
**Batch videos + code:** Watch 20–30 mins → pause → write *1 line summary* + do 1 small code snippet.

Good luck, you’ve GOT this! 💪🚀

